{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "This notebook will focus on extracting features from the preprocessed text data using TF-IDF, Word2Vec, and Sentence Transformers. The extracted featurees will be used in the subsequent notebook for model training and evaluation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import pickle\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "import multiprocessing\n",
    "from time import time\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from scipy import sparse"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the preprocessed dataframe from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_text</th>\n",
       "      <th>Word2Vec</th>\n",
       "      <th>TF-IDF</th>\n",
       "      <th>SentenceTrans</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I LOVE my 10 &amp;amp; 5 but most days they remind...</td>\n",
       "      <td>I LOVE my 10 &amp;amp; 5 but most days they remind...</td>\n",
       "      <td>[love, my, amp, but, most, day, they, remind, ...</td>\n",
       "      <td>love my amp but most day they remind me why bi...</td>\n",
       "      <td>i love my  amp  but most days they remind me w...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>She be thinking she throwing that pussy back s...</td>\n",
       "      <td>She be thinking she throwing that pussy back s...</td>\n",
       "      <td>[she, be, think, she, throw, that, pussy, back...</td>\n",
       "      <td>she be think she throw that pussy back so good...</td>\n",
       "      <td>she be thinking she throwing that pussy back s...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @lamessican: I love when bitches throw shad...</td>\n",
       "      <td>I love when bitches throw shade. Just confirms...</td>\n",
       "      <td>[love, when, bitch, throw, shade, just, confir...</td>\n",
       "      <td>love when bitch throw shade just confirm do so...</td>\n",
       "      <td>i love when bitches throw shade just confirms ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>If you ain't a hoe, get up out my trap house @...</td>\n",
       "      <td>If you ain't a hoe, get up out my trap house .</td>\n",
       "      <td>[if, you, ain, hoe, get, up, out, my, trap, ho...</td>\n",
       "      <td>if you ain hoe get up out my trap house</td>\n",
       "      <td>if you aint a hoe get up out my trap house</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Just hit 40 in flappy bird.&amp;#128527;</td>\n",
       "      <td>Just hit 40 in flappy bird.&amp;#128527;</td>\n",
       "      <td>[just, hit, in, flappy, bird]</td>\n",
       "      <td>just hit in flappy bird</td>\n",
       "      <td>just hit  in flappy bird</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet  \\\n",
       "0      0  I LOVE my 10 &amp; 5 but most days they remind...   \n",
       "1      1  She be thinking she throwing that pussy back s...   \n",
       "2      1  RT @lamessican: I love when bitches throw shad...   \n",
       "3      1  If you ain't a hoe, get up out my trap house @...   \n",
       "4      0               Just hit 40 in flappy bird.&#128527;   \n",
       "\n",
       "                                        cleaned_text  \\\n",
       "0  I LOVE my 10 &amp; 5 but most days they remind...   \n",
       "1  She be thinking she throwing that pussy back s...   \n",
       "2  I love when bitches throw shade. Just confirms...   \n",
       "3     If you ain't a hoe, get up out my trap house .   \n",
       "4               Just hit 40 in flappy bird.&#128527;   \n",
       "\n",
       "                                            Word2Vec  \\\n",
       "0  [love, my, amp, but, most, day, they, remind, ...   \n",
       "1  [she, be, think, she, throw, that, pussy, back...   \n",
       "2  [love, when, bitch, throw, shade, just, confir...   \n",
       "3  [if, you, ain, hoe, get, up, out, my, trap, ho...   \n",
       "4                      [just, hit, in, flappy, bird]   \n",
       "\n",
       "                                              TF-IDF  \\\n",
       "0  love my amp but most day they remind me why bi...   \n",
       "1  she be think she throw that pussy back so good...   \n",
       "2  love when bitch throw shade just confirm do so...   \n",
       "3            if you ain hoe get up out my trap house   \n",
       "4                            just hit in flappy bird   \n",
       "\n",
       "                                       SentenceTrans  \n",
       "0  i love my  amp  but most days they remind me w...  \n",
       "1  she be thinking she throwing that pussy back s...  \n",
       "2  i love when bitches throw shade just confirms ...  \n",
       "3        if you aint a hoe get up out my trap house   \n",
       "4                           just hit  in flappy bird  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "with open('data/df_balanced.pkl', 'rb') as f:\n",
    "    df_balanced = pickle.load(f)\n",
    "\n",
    "df_balanced.head()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Vectorize the Text Data\n",
    "Convert the preprocessed text data to vector representations."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### TF-IDF"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Parameters:\n",
    "1. `min_df`: minimum document frequency\n",
    "    \n",
    "    Ignore terms with document frequency lower than 3 documents.\n",
    "2. `ngram_range`: n-values for n-grams to be extracted\n",
    "    \n",
    "    Extract unigrams and bigrams."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = TfidfVectorizer(min_df = 3, ngram_range= (1,2))\n",
    "x_tfidf = vectorizer.fit_transform(df_balanced['TF-IDF'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(8326, 7924)\n"
     ]
    }
   ],
   "source": [
    "print(x_tfidf.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the text representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save the sparse matrix to a .npz file\n",
    "sparse.save_npz('x_tfidf.npz', x_tfidf)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Word2Vec"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Setting up Model Parameters\n",
    "1. `min_count`: minimum frequency of words\n",
    "\n",
    "    Ignore terms with frequency count lower than 3.\n",
    "2. `window`: context window size\n",
    "\n",
    "    Set to 5 to balance between syntactic context and broader semantic relationships.\n",
    "3. `vector_size`: dimensionality of the feature vectors\n",
    "\n",
    "    Set to 100 for reduced computational load.\n",
    "4. `sample`: threshold for downsampling of higher-frequency words\n",
    "\n",
    "    Set to 6e-5 for a higher threshold for less aggressive downsampling.\n",
    "5. `alpha`: initial learning rate\n",
    "\n",
    "    Set to 0.03 for faster convergence.\n",
    "6. `min_alpha`: as training progresses, learning rate decreases linearly from `alpha` to `min_alpha`\n",
    "\n",
    "    Set to 0.0007.\n",
    "7. `negative`: negative sampling distinguishes between genuine context words and noise\n",
    "\n",
    "    Set to 10 for reduced computational load.\n",
    "8. `workers`: number of CPU cores used during training, impacting speed\n",
    "\n",
    "    Set to cores-1 to utilise most of the system's processing power.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "cores = multiprocessing.cpu_count() # Count the number of cores in a computer\n",
    "\n",
    "w2v_model = Word2Vec(min_count=3, \n",
    "                     window=5, \n",
    "                     vector_size=100,\n",
    "                     sample=6e-5,\n",
    "                     alpha=0.03,\n",
    "                     min_alpha=0.0007,\n",
    "                     negative=10,\n",
    "                     workers=cores-1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Building the Vocabulary Table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to build vocab:0.0 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "w2v_model.build_vocab(df_balanced['Word2Vec'])\n",
    "print(f'Time to build vocab:{round((time()-t)/60, 2)} mins')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Time to train the model: 0.02 mins\n"
     ]
    }
   ],
   "source": [
    "t = time()\n",
    "w2v_model.train(df_balanced['Word2Vec'], total_examples=w2v_model.corpus_count, epochs=30)\n",
    "print('Time to train the model: {} mins'.format(round((time() - t) / 60, 2)))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generate Sentence Vectors"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_sentence_vector(text):\n",
    "    word_vectors = [w2v_model.wv[word] for word in text if word in w2v_model.wv]\n",
    "    if len(word_vectors) == 0:\n",
    "        return np.zeros(w2v_model.vector_size)\n",
    "    else:\n",
    "        return np.mean(word_vectors, axis=0)\n",
    "    \n",
    "\n",
    "x_w2v = np.array([get_sentence_vector(text) for text in df_balanced['Word2Vec']])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the text representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('representations/x_w2v.npy', x_w2v)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Sentence Transformers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Generating sentence embeddings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\danie\\VSCode Projects\\Text Representation\\TextRep-Performance\\venv\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "9a5ad7c078104f0081fbb680c7df989c",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "Batches:   0%|          | 0/261 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "sentence_model = SentenceTransformer(\"all-MiniLM-L6-v2\")\n",
    "x_ST = sentence_model.encode(df_balanced['SentenceTrans'], show_progress_bar=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Verifying the embeddings are a NumPy array"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'numpy.ndarray'>\n"
     ]
    }
   ],
   "source": [
    "print(type(x_ST))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Saving the text representations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save('representations/x_ST.npy', x_ST)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
