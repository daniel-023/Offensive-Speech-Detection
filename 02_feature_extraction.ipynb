{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Feature Extraction\n",
    "This notebook will focus on extracting features from the preprocessed text data using TF-IDF, Word2Vec, and Sentence Transformers. The extracted featurees will be used in the subsequent notebook for model training and evaluation.  "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Set Up Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.feature_extraction.text import TfidfVectorizer\n",
    "from gensim.models import Word2Vec\n",
    "from sentence_transformers import SentenceTransformer"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's load the preprocessed dataframe from the previous notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>class</th>\n",
       "      <th>tweet</th>\n",
       "      <th>cleaned_text</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>0</td>\n",
       "      <td>I LOVE my 10 &amp;amp; 5 but most days they remind...</td>\n",
       "      <td>['love', 'my', 'amp', 'but', 'most', 'days', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>She be thinking she throwing that pussy back s...</td>\n",
       "      <td>['she', 'be', 'thinking', 'she', 'throwing', '...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @lamessican: I love when bitches throw shad...</td>\n",
       "      <td>['love', 'when', 'bitches', 'throw', 'shade', ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>If you ain't a hoe, get up out my trap house @...</td>\n",
       "      <td>['if', 'you', 'ain', 'hoe', 'get', 'up', 'out'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0</td>\n",
       "      <td>Just hit 40 in flappy bird.&amp;#128527;</td>\n",
       "      <td>['just', 'hit', 'in', 'flappy', 'bird']</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>0</td>\n",
       "      <td>WEBBERS! RT @DMILZ4: Sz13 vnds restorers dream...</td>\n",
       "      <td>['sz', 'vnds', 'restorers', 'dream', 'cracked'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>0</td>\n",
       "      <td>RT @jemelehill: Just saw Dawn of The Planet of...</td>\n",
       "      <td>['just', 'saw', 'dawn', 'of', 'the', 'planet',...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7</th>\n",
       "      <td>1</td>\n",
       "      <td>RT @femaIes: I swear &amp;#128514; we in this fore...</td>\n",
       "      <td>['swear', 'we', 'in', 'this', 'forever', 'now'...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>8</th>\n",
       "      <td>0</td>\n",
       "      <td>Moral to the story: If you like the Yanks, I'l...</td>\n",
       "      <td>['if', 'you', 'like', 'the', 'yanks', 'll', 'p...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>9</th>\n",
       "      <td>1</td>\n",
       "      <td>Dayum u gyp, u gone have mfs thinking im wipin...</td>\n",
       "      <td>['dayum', 'gyp', 'gone', 'have', 'mfs', 'think...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   class                                              tweet  \\\n",
       "0      0  I LOVE my 10 &amp; 5 but most days they remind...   \n",
       "1      1  She be thinking she throwing that pussy back s...   \n",
       "2      1  RT @lamessican: I love when bitches throw shad...   \n",
       "3      1  If you ain't a hoe, get up out my trap house @...   \n",
       "4      0               Just hit 40 in flappy bird.&#128527;   \n",
       "5      0  WEBBERS! RT @DMILZ4: Sz13 vnds restorers dream...   \n",
       "6      0  RT @jemelehill: Just saw Dawn of The Planet of...   \n",
       "7      1  RT @femaIes: I swear &#128514; we in this fore...   \n",
       "8      0  Moral to the story: If you like the Yanks, I'l...   \n",
       "9      1  Dayum u gyp, u gone have mfs thinking im wipin...   \n",
       "\n",
       "                                        cleaned_text  \n",
       "0  ['love', 'my', 'amp', 'but', 'most', 'days', '...  \n",
       "1  ['she', 'be', 'thinking', 'she', 'throwing', '...  \n",
       "2  ['love', 'when', 'bitches', 'throw', 'shade', ...  \n",
       "3  ['if', 'you', 'ain', 'hoe', 'get', 'up', 'out'...  \n",
       "4            ['just', 'hit', 'in', 'flappy', 'bird']  \n",
       "5  ['sz', 'vnds', 'restorers', 'dream', 'cracked'...  \n",
       "6  ['just', 'saw', 'dawn', 'of', 'the', 'planet',...  \n",
       "7  ['swear', 'we', 'in', 'this', 'forever', 'now'...  \n",
       "8  ['if', 'you', 'like', 'the', 'yanks', 'll', 'p...  \n",
       "9  ['dayum', 'gyp', 'gone', 'have', 'mfs', 'think...  "
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_balanced = pd.read_csv('data/df_balanced.csv')\n",
    "df_balanced.head(10)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Prepare Data for Feature Extraction"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We split the data into a 80/20 train-test split."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train, X_test, y_train, y_test = train_test_split(df_balanced['cleaned_text'], df_balanced['class'], test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## TF-IDF"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
